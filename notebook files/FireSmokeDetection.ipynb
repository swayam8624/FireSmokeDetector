{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the training and validation datasets\n",
        "train_data = np.load('train_data.npz')\n",
        "train_images = train_data['images']\n",
        "train_labels = train_data['labels']\n",
        "\n",
        "val_data = np.load('val_data.npz')\n",
        "val_images = val_data['images']\n",
        "val_labels = val_data['labels']\n",
        "\n",
        "# Now you can use train_images, train_labels, val_images, and val_labels for model training"
      ],
      "metadata": {
        "id": "zj4P9rHaOOVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the image size\n",
        "IMG_SIZE = 224\n",
        "# Build the CNN model\n",
        "model = models.Sequential()\n",
        "\n",
        "# First convolutional layer\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Second convolutional layer\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Third convolutional layer\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flattening the layers\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))  # Adding dropout to prevent overfitting\n",
        "model.add(layers.Dense(3, activation='softmax'))  # Assuming 3 classes: fire, smoke, no_fire_smoke\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "_x-iQY3Acpfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc8b5600-e8cd-451c-974e-cc3915aced74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 111, 111, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 109, 109, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 54, 54, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 52, 52, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 26, 26, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 86528)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               11075712  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11169347 (42.61 MB)\n",
            "Trainable params: 11169347 (42.61 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=10, batch_size=16, validation_data=(val_images, val_labels),verbose=1)"
      ],
      "metadata": {
        "id": "t2cm9E-2cusJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b2b7352-7d33-4192-cfd5-6b30ca49c770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1620/1620 [==============================] - 400s 246ms/step - loss: 0.4106 - accuracy: 0.8572 - val_loss: 0.3402 - val_accuracy: 0.8787\n",
            "Epoch 2/10\n",
            "1620/1620 [==============================] - 388s 240ms/step - loss: 0.2907 - accuracy: 0.8969 - val_loss: 0.3139 - val_accuracy: 0.8907\n",
            "Epoch 3/10\n",
            "1620/1620 [==============================] - 385s 238ms/step - loss: 0.2294 - accuracy: 0.9166 - val_loss: 0.3257 - val_accuracy: 0.8981\n",
            "Epoch 4/10\n",
            "1620/1620 [==============================] - 387s 239ms/step - loss: 0.1833 - accuracy: 0.9328 - val_loss: 0.3672 - val_accuracy: 0.8966\n",
            "Epoch 5/10\n",
            "1620/1620 [==============================] - 382s 236ms/step - loss: 0.1668 - accuracy: 0.9405 - val_loss: 0.3989 - val_accuracy: 0.8974\n",
            "Epoch 6/10\n",
            "1620/1620 [==============================] - 381s 235ms/step - loss: 0.1482 - accuracy: 0.9453 - val_loss: 0.5610 - val_accuracy: 0.8969\n",
            "Epoch 7/10\n",
            "1620/1620 [==============================] - 380s 234ms/step - loss: 0.1435 - accuracy: 0.9456 - val_loss: 0.4798 - val_accuracy: 0.8964\n",
            "Epoch 8/10\n",
            "1620/1620 [==============================] - 380s 234ms/step - loss: 0.1393 - accuracy: 0.9477 - val_loss: 0.5467 - val_accuracy: 0.8971\n",
            "Epoch 9/10\n",
            "1620/1620 [==============================] - 379s 234ms/step - loss: 0.1395 - accuracy: 0.9484 - val_loss: 0.5728 - val_accuracy: 0.8963\n",
            "Epoch 10/10\n",
            "1620/1620 [==============================] - 381s 235ms/step - loss: 0.1354 - accuracy: 0.9484 - val_loss: 0.6418 - val_accuracy: 0.8978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_acc = model.evaluate(val_images, val_labels, verbose=2)\n",
        "print(f\"Validation Accuracy: {val_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "4tuXtgyFUBQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a335bcf-c38e-4995-fdf5-2b6bbeb7a25b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "203/203 - 17s - loss: 0.6418 - accuracy: 0.8978 - 17s/epoch - 82ms/step\n",
            "Validation Accuracy: 89.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('fire_smoke_detector.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raiCIbFelZTP",
        "outputId": "931479a1-c41b-4220-bcb4-968eca9d742a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('fire_smoke_detector.h5')"
      ],
      "metadata": {
        "id": "EBnJKxYi6ZSS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_frame(frame):\n",
        "    frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n",
        "    frame = frame.astype('float32') / 255.0\n",
        "    frame = np.expand_dims(frame, axis=0)\n",
        "    return frame"
      ],
      "metadata": {
        "id": "SrimnBEK7WgS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def process_rtsp_stream(rtsp_url, model):\n",
        "    cap = cv2.VideoCapture(rtsp_url)\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        preprocessed_frame = preprocess_frame(frame)\n",
        "        prediction = model.predict(preprocessed_frame)\n",
        "        class_index = np.argmax(prediction)\n",
        "        labels = [\"Fire\", \"Smoke\", \"No Fire/Smoke\"]\n",
        "        label = labels[class_index]\n",
        "        cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "        cv2.imshow(rtsp_url, frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "# List of RTSP streams\n",
        "rtsp_streams = [\"rtsp://stream1\", \"rtsp://stream2\", \"rtsp://stream3\"]\n",
        "\n",
        "# Launch a thread for each stream\n",
        "threads = []\n",
        "for stream in rtsp_streams:\n",
        "    thread = threading.Thread(target=process_rtsp_stream, args=(stream, model))\n",
        "    thread.start()\n",
        "    threads.append(thread)\n",
        "\n",
        "for thread in threads:\n",
        "    thread.join()\n",
        "\n"
      ],
      "metadata": {
        "id": "h1q5-60l6mGA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hxt2Av846o96"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}