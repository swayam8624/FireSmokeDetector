{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f4c7dd6-cba0-419a-9026-56907210c5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_images_from_directories(path_fire, path_smoke, path_no_fire_smoke, IMG_SIZE=224):\n",
    "    images = []\n",
    "    labels = []\n",
    "    image_extensions = ['jpg', 'jpeg', 'png', 'tif', 'tiff'] \n",
    "\n",
    "    for path, label in [(path_fire, 1), (path_smoke, 2), (path_no_fire_smoke, 0)]:\n",
    "        print(f\"Processing directory: {path}\")\n",
    "        for file in os.listdir(path):\n",
    "            if file.split('.')[-1].lower() in image_extensions:\n",
    "                img_path = os.path.join(path, file)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)  # Use IMREAD_UNCHANGED for .tif images\n",
    "                if img is not None:\n",
    "                    # Check if the image is grayscale (2D) and convert to 3 channels if needed\n",
    "                    if len(img.shape) == 2:\n",
    "                        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "                    elif img.shape[2] == 4:  # For images with 4 channels (e.g., RGBA)\n",
    "                        img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "                    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                    images.append(img)\n",
    "                    labels.append(label)\n",
    "                    # print(f\"Loaded image: {img_path}\")\n",
    "                else:\n",
    "                    print(f\"Failed to read image: {img_path}\")\n",
    "            else:\n",
    "                print(f\"Skipped file (not an image): {file}\")\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1365a51d-041a-4cd1-9db0-29bb47dca5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your directory paths here\n",
    "path_fire = 'datasets/FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET/train/fire/'  # Replace with the actual path\n",
    "path_smoke = 'datasets/FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET/train/Smoke/'  # Replace with the actual path\n",
    "path_no_fire_smoke = 'datasets/FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET/train/non fire/'  # Replace with the actual path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f52533d-2334-4bf0-b23f-a0135913e127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing directory: datasets/FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET/train/fire/\n",
      "Skipped file (not an image): .DS_Store\n",
      "Skipped file (not an image): Fire (3).gif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid SOS parameters for sequential JPEG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to read image: datasets/FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET/train/fire/Fire (4156).jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped file (not an image): Fire (1).gif\n",
      "Processing directory: datasets/FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET/train/Smoke/\n",
      "Skipped file (not an image): .DS_Store\n",
      "Processing directory: datasets/FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET/train/non fire/\n",
      "Skipped file (not an image): .DS_Store\n",
      "Failed to read image: datasets/FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET/train/non fire/Non_Fire (307).png\n",
      "Failed to read image: datasets/FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET/train/non fire/Non_Fire (6758).jpg\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224  # Desired image size (224x224)\n",
    "images, labels = load_images_from_directories(path_fire, path_smoke, path_no_fire_smoke, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54919ad0-9db8-4bd2-aab5-6a5cd9dce8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (32395, 224, 224, 3)\n",
      "Labels shape: (32395,)\n"
     ]
    }
   ],
   "source": [
    "# Convert lists to NumPy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "images = images.astype('float32') / 255.0\n",
    "\n",
    "# Print shape to verify\n",
    "print(f\"Images shape: {images.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de7b9e3c-460d-4891-9bf7-ad7f9ad09abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (25916, 224, 224, 3)\n",
      "Validation data shape: (6479, 224, 224, 3)\n",
      "Training labels shape: (25916,)\n",
      "Validation labels shape: (6479,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and validation sets (e.g., 80% training, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print shapes of the resulting sets\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Validation labels shape: {y_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a6901ba-a304-4f79-ac53-1a5b0c5792aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.uint8)  \n",
    "y_train = y_train.astype(np.uint8) \n",
    "X_val = X_val.astype(np.uint8) \n",
    "y_val = y_val.astype(np.uint8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a64711-2092-44f5-ae34-9747cdebfc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('train_data.npz', images=X_train, labels=y_train)\n",
    "np.savez_compressed('val_data.npz', images=X_val, labels=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d899f44d-ea83-4e37-bf83-623b027faf60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
